{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b38199b1",
   "metadata": {},
   "source": [
    "### Deep learning inference\n",
    "\n",
    "- Detect tree objects from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urbantree.setting import Setting\n",
    "\n",
    "#SETTING = \"settings/by_dop80c_1312/deepforest_r1/setting.yaml\"\n",
    "#SETTING = \"settings/by_dop80c_1312/deepforest_r2/setting.yaml\"\n",
    "SETTING = \"settings/by_dop80c_1312/deepforest_r3/setting.yaml\"\n",
    "#SETTING = \"settings/opendata_luftbild_dop60_1312/deepforest_r1/setting.yaml\"\n",
    "#SETTING = \"settings/opendata_luftbild_dop60_1312/deepforest_r2/setting.yaml\"\n",
    "#SETTING = \"settings/opendata_luftbild_dop60_1312/deepforest_r3/setting.yaml\"\n",
    "\n",
    "setting = Setting.load_deepforest_setting(SETTING)\n",
    "setting['model_inference_config']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1465225",
   "metadata": {},
   "source": [
    "- detect tree objects from dataset and the resulting bounding boxes DataFrame are saved in pickle objects.\n",
    "- The object detection can be performed on different patch sizes and\n",
    "  no extra nms is run on aggregated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3969980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urbantree.deepforest.detection import infer_images\n",
    "\n",
    "infer_images(**setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e4502",
   "metadata": {},
   "source": [
    "- Render tree canopy raster images according to the resulting bounding boxes DataFrame saved in pickle objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b64c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urbantree.deepforest.detection import postprocess_render_images\n",
    "\n",
    "dataset_img_pattern=\"*.tiff\"\n",
    "#dataset_img_pattern = \"*6128569*\"\n",
    "#dataset_img_pattern = \"*1287912.570476842_*\"\n",
    "\n",
    "postprocess_render_images(**setting,\n",
    "                          dataset_img_pattern=dataset_img_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4f5ec",
   "metadata": {},
   "source": [
    "- calculate difference among two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7423ed7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIFF_FROM_INFERENCE_PARAM {'confident_min_bbox_size': 64, 'confident_min_score': 0.6, 'morphology_factor': 1, 'concurrency': 4, 'patch': [{'patch_size': 1200, 'patch_overlap': 0.3, 'iou_threshold': 0.8, 'score_thresh': 0.9}, {'patch_size': 800, 'patch_overlap': 0.3, 'iou_threshold': 0.8, 'score_thresh': 0.55}, {'patch_size': 200, 'patch_overlap': 0.2, 'iou_threshold': 0.7, 'score_thresh': 0.45}, {'patch_size': 96, 'patch_overlap': 0.18, 'iou_threshold': 0.6, 'score_thresh': 0.45}]}\n",
      "DIFF_TO_INFERENCE_PARAM {'confident_min_bbox_size': 64, 'confident_min_score': 0.6, 'morphology_factor': 1, 'concurrency': 4, 'patch': [{'patch_size': 1200, 'patch_overlap': 0.3, 'iou_threshold': 0.8, 'score_thresh': 0.45}, {'patch_size': 800, 'patch_overlap': 0.3, 'iou_threshold': 0.8, 'score_thresh': 0.25}, {'patch_size': 200, 'patch_overlap': 0.2, 'iou_threshold': 0.7, 'score_thresh': 0.1}, {'patch_size': 96, 'patch_overlap': 0.18, 'iou_threshold': 0.6, 'score_thresh': 0.1}]}\n"
     ]
    }
   ],
   "source": [
    "from urbantree.deepforest.detection import calc_diff\n",
    "\n",
    "# tune inference parameter to increase precision rate of diff result\n",
    "DIFF_FROM_INFERENCE_PARAM = {\n",
    "  'confident_min_bbox_size': 64, \n",
    "  'confident_min_score': 0.6, \n",
    "  'morphology_factor': 1, \n",
    "  'concurrency': 4, \n",
    "  'patch': [\n",
    "    {\n",
    "      'patch_size': 1200, \n",
    "      'patch_overlap': 0.3, \n",
    "      'iou_threshold': 0.8, \n",
    "      'score_thresh': 0.9\n",
    "    }, \n",
    "    {\n",
    "      'patch_size': 800, \n",
    "      'patch_overlap': 0.3, \n",
    "      'iou_threshold': 0.8, \n",
    "      'score_thresh': 0.55\n",
    "    }, \n",
    "    {\n",
    "      'patch_size': 200, \n",
    "      'patch_overlap': 0.2, \n",
    "      'iou_threshold': 0.7, \n",
    "      'score_thresh': 0.45\n",
    "    }, \n",
    "    {\n",
    "      'patch_size': 96, \n",
    "      'patch_overlap': 0.18, \n",
    "      'iou_threshold': 0.6, \n",
    "      'score_thresh': 0.45\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "DIFF_TO_INFERENCE_PARAM = {\n",
    "  'confident_min_bbox_size': 64,\n",
    "  'confident_min_score': 0.6, \n",
    "  'morphology_factor': 1, \n",
    "  'concurrency': 4, \n",
    "  'patch': [\n",
    "    {\n",
    "      'patch_size': 1200, \n",
    "      'patch_overlap': 0.3, \n",
    "      'iou_threshold': 0.8, \n",
    "      'score_thresh': 0.45\n",
    "    }, \n",
    "    {\n",
    "      'patch_size': 800, \n",
    "      'patch_overlap': 0.3, \n",
    "      'iou_threshold': 0.8, \n",
    "      'score_thresh': 0.25\n",
    "    }, \n",
    "    {\n",
    "      'patch_size': 200, \n",
    "      'patch_overlap': 0.2, \n",
    "      'iou_threshold': 0.7, \n",
    "      'score_thresh': 0.1\n",
    "    }, \n",
    "    {\n",
    "      'patch_size': 96, \n",
    "      'patch_overlap': 0.18, \n",
    "      'iou_threshold': 0.6, \n",
    "      'score_thresh': 0.1\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "calc_diff(diff_from_setting_path=\"settings/opendata_luftbild_dop60_1312/deepforest_r2/setting.yaml\",\n",
    "          diff_to_setting_path=\"settings/by_dop80c_1312/deepforest_r3/setting.yaml\",\n",
    "          diff_from_inference_param=DIFF_FROM_INFERENCE_PARAM,\n",
    "          diff_to_inference_param=DIFF_TO_INFERENCE_PARAM,\n",
    "          aggregate_iou_threshold=0.4,\n",
    "          diff_iou_threshold=0.1,\n",
    "          diff_cover_threshold=0.4,\n",
    "          output_bbox_dir='temp/diff2/b',\n",
    "          output_debug_img_dir='temp/diff2/debug',\n",
    "          concurrency=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca3da448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1463/1463 [00:47<00:00, 30.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows before NMS: 36020\n",
      "rows after NMS: 32507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [09:55<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows before NMS: 1125282\n"
     ]
    }
   ],
   "source": [
    "from urbantree.deepforest.detection import create_bbox_geojson\n",
    "\n",
    "create_bbox_geojson(src_img_dir='aerial_images_resampled/opendata_luftbild_dop60_1312',\n",
    "                    src_bbox_dif='temp/diff2/b/diff',\n",
    "                    output_geojson_path='temp/diff2/diff.geojson',\n",
    "                    output_pkl_path='temp/diff2/diff.pkl',\n",
    "                    size_threshold=200, # show only larger trees\n",
    "                    iou_threshold=0.4)\n",
    "\n",
    "create_bbox_geojson(src_img_dir='aerial_images_resampled/opendata_luftbild_dop60_1312',\n",
    "                    src_bbox_dif='temp/diff2/b/from',\n",
    "                    output_geojson_path='temp/diff2/from.geojson',\n",
    "                    output_pkl_path='temp/diff2/from.pkl',\n",
    "                    size_threshold=110, # exclude very small tree\n",
    "                    iou_threshold=0.4)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d17c320a108ed353692a9d869777d22c4cfc8e217512b3979b490c9a0e17a049"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
