{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b38199b1",
   "metadata": {},
   "source": [
    "### Deep learning inference\n",
    "\n",
    "- Detect tree objects from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urbantree.setting import Setting\n",
    "\n",
    "#SETTING = \"settings/by_dop80c_1312/deepforest_r1/setting.yaml\"\n",
    "#SETTING = \"settings/by_dop80c_1312/deepforest_r2/setting.yaml\"\n",
    "#SETTING = \"settings/by_dop80c_1312/deepforest_r3/setting.yaml\"\n",
    "#SETTING = \"settings/opendata_luftbild_dop60_1312/deepforest_r1/setting.yaml\"\n",
    "#SETTING = \"settings/opendata_luftbild_dop60_1312/deepforest_r2/setting.yaml\"\n",
    "SETTING = \"settings/opendata_luftbild_dop60_1312/deepforest_r3/setting.yaml\"\n",
    "\n",
    "setting = Setting.load_deepforest_setting(SETTING)\n",
    "setting['model_inference_config']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1465225",
   "metadata": {},
   "source": [
    "- detect tree objects from dataset and the resulting bounding boxes DataFrame are saved in pickle objects.\n",
    "- The object detection can be performed on different patch sizes and\n",
    "  no extra nms is run on aggregated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3969980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urbantree.deepforest.detection import infer_images\n",
    "\n",
    "infer_images(**setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e4502",
   "metadata": {},
   "source": [
    "- Render tree canopy raster images according to the resulting bounding boxes DataFrame saved in pickle objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b64c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urbantree.deepforest.detection import postprocess_render_images\n",
    "\n",
    "dataset_img_pattern=\"*.tiff\"\n",
    "\n",
    "postprocess_render_images(**setting,\n",
    "                          dataset_img_pattern=dataset_img_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4f5ec",
   "metadata": {},
   "source": [
    "- calculate difference among two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7423ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urbantree.deepforest.detection import calc_diff\n",
    "\n",
    "# tune inference parameters to increase outcome\n",
    "diff_from_inference_param = {\n",
    "  'confident_min_bbox_size': 20,\n",
    "  'confident_min_score': 0.9,\n",
    "  'morphology_factor': 1,\n",
    "  'patch': [\n",
    "    {'patch_size': 1200,\n",
    "    'patch_overlap': 0.3,\n",
    "    'iou_threshold': 0.8,\n",
    "    'score_thresh': 0.95},\n",
    "    {'patch_size': 800,\n",
    "    'patch_overlap': 0.3,\n",
    "    'iou_threshold': 0.8,\n",
    "    'score_thresh': 0.9},\n",
    "    {'patch_size': 200,\n",
    "    'patch_overlap': 0.2,\n",
    "    'iou_threshold': 0.7,\n",
    "    'score_thresh': 0.8},\n",
    "    {'patch_size': 96,\n",
    "    'patch_overlap': 0.18,\n",
    "    'iou_threshold': 0.6,\n",
    "    'score_thresh': 0.8}]}\n",
    "diff_to_inference_param = {\n",
    "  'confident_min_bbox_size': 30,\n",
    "  'confident_min_score': 0.8,\n",
    "  'morphology_factor': 3,\n",
    "  'patch': [\n",
    "    {'patch_size': 1200,\n",
    "    'patch_overlap': 0.3,\n",
    "    'iou_threshold': 0.8,\n",
    "    'score_thresh': 0.2},\n",
    "    {'patch_size': 800,\n",
    "    'patch_overlap': 0.3,\n",
    "    'iou_threshold': 0.8,\n",
    "    'score_thresh': 0.1},\n",
    "    {'patch_size': 200,\n",
    "    'patch_overlap': 0.2,\n",
    "    'iou_threshold': 0.7,\n",
    "    'score_thresh': 0.01},\n",
    "    {'patch_size': 96,\n",
    "    'patch_overlap': 0.18,\n",
    "    'iou_threshold': 0.6,\n",
    "    'score_thresh': 0.01}]}\n",
    "\n",
    "calc_diff(diff_from_setting_path=\"settings/opendata_luftbild_dop60_1312/deepforest_r3/setting.yaml\",\n",
    "          diff_to_setting_path=\"settings/by_dop80c_1312/deepforest_r2/setting.yaml\",\n",
    "          aggregate_iou_threshold=0.4,\n",
    "          diff_iou_threshold=0.08,\n",
    "          diff_cover_threshold=0.1,\n",
    "          diff_from_inference_param=diff_from_inference_param,\n",
    "          diff_to_inference_param=diff_to_inference_param,\n",
    "          output_bbox_dir='temp/diff/b',\n",
    "          output_debug_img_dir='temp/diff/debug',\n",
    "          concurrency=11) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accfde34",
   "metadata": {},
   "source": [
    "- generate bbox output for mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca3da448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1474/1474 [00:56<00:00, 25.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 20502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1492/1492 [15:14<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 935209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1484/1484 [13:24<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 842348\n"
     ]
    }
   ],
   "source": [
    "from urbantree.deepforest.detection import create_bbox_shapefile\n",
    "\n",
    "create_bbox_shapefile(src_img_dir='aerial_images_resampled/opendata_luftbild_dop60_1312',\n",
    "                    src_bbox_diff='temp/diff/b/diff',\n",
    "                    output_shp_path='temp/diff/diff.shp',\n",
    "                    size_min_threshold=200, \n",
    "                    iou_threshold=0.2)\n",
    "\n",
    "create_bbox_shapefile(src_img_dir='aerial_images_resampled/opendata_luftbild_dop60_1312',\n",
    "                    src_bbox_diff='interim/opendata_luftbild_dop60_1312/deepforest_r3/inference/b',\n",
    "                    output_shp_path='temp/diff/2017.shp',\n",
    "                    size_min_threshold=200,\n",
    "                    iou_threshold=0.3)\n",
    "\n",
    "create_bbox_shapefile(src_img_dir='aerial_images_resampled/opendata_luftbild_dop60_1312',\n",
    "                    src_bbox_diff='interim/by_dop80c_1312/deepforest_r2/inference/b',\n",
    "                    output_shp_path='temp/diff/2020.shp',\n",
    "                    size_min_threshold=200,\n",
    "                    iou_threshold=0.3)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d17c320a108ed353692a9d869777d22c4cfc8e217512b3979b490c9a0e17a049"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
