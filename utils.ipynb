{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some handy util tools\n",
    "\n",
    "each cell should provide different functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copy all training images specified in split.csv to another folder\n",
    "import pandas as pd\n",
    "import shutil \n",
    "SPLIT_CSV          = 'interim/by_dop80c_1312.split.csv'\n",
    "DEST_TRAINING_PATH = 'interim/by_dop80c_1312'\n",
    "split_df = pd.read_csv(SPLIT_CSV)\n",
    "for index, d in split_df[split_df['train']].iterrows():\n",
    "  #print (d.img_filepath)\n",
    "  shutil.copy(d.img_filepath, DEST_TRAINING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy files\n",
    "import shutil \n",
    "from pathlib import Path \n",
    "import os\n",
    "\n",
    "ds = 'by_dop80c_1312' # 'opendata_luftbild_dop60_1312'\n",
    "FROM_DIR = Path('aerial_images_resampled/{ds}'.format(ds=ds))\n",
    "DST_DIR = Path('interim/{ds}/deepforest_r1/train2'.format(ds=ds))\n",
    "PATTERN = [\n",
    " '1288638.722245550_6129295.399946138_1289422.201785473_6130078.879486061.tiff',\n",
    " '1288638.722245550_6128569.248177430_1289422.201785473_6129352.727717352.tiff',\n",
    " '1290091.025782968_6128569.248177430_1290874.505322890_6129352.727717352.tiff',\n",
    " '1290817.177551676_6127843.096408719_1291600.657091599_6128626.575948643.tiff',\n",
    " '1287186.418708133_6127116.944640011_1287969.898248056_6127900.424179933.tiff',\n",
    " '1290091.025782968_6127843.096408719_1290874.505322890_6128626.575948643.tiff',\n",
    " '1289364.874014259_6128569.248177430_1290148.353554182_6129352.727717352.tiff',\n",
    " '1287912.570476842_6129295.399946138_1288696.050016765_6130078.879486061.tiff',\n",
    " '1288638.722245550_6130021.551714847_1289422.201785473_6130805.031254769.tiff']\n",
    "os.makedirs(DST_DIR, exist_ok=True)\n",
    "for pattern in PATTERN:\n",
    "  for s in FROM_DIR.glob(pattern):\n",
    "    print(s)\n",
    "    shutil.copy(s, DST_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downsampling map tiles from a higher zoom level down to specified lower zoom levels \n",
    "# \n",
    "import mercantile\n",
    "import supermercado\n",
    "import rasterio\n",
    "from rasterio import plot, transform\n",
    "import numpy\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "AREA = 'munich.boundary.geojson'\n",
    "SRC_ZOOM = 11\n",
    "SOURCE_MAP_TILE_BAND_COUNT = 4\n",
    "SOURCE_MAP_TILE_WIDTH_PX   = 256 \n",
    "SOURCE_MAP_TILE_HEIGHT_PX  = 256\n",
    "SOURCE_MAP_TILE_DTYPE      = numpy.uint8\n",
    "SOURCE_MAP_TILE_TYPE       = \".tiff\"\n",
    "OUTPUT_ZOOMS               = range(0, SRC_ZOOM)\n",
    "SOURCE_MAP_TILE_PATH       = 'aerial_images/opendata_luftbild_dop60_2017'\n",
    "OUTPUT_TILE_PATH           = 'aerial_images/opendata_luftbild_dop60_2017'\n",
    "SOURCE_MAP_TILE_EPSG       = 3857 # only epsg:3857 is supported\n",
    "\n",
    "f = open(AREA)\n",
    "area = json.load(f)\n",
    "f.close()\n",
    "\n",
    "features = area[\"features\"]\n",
    "features = [f for f in supermercado.super_utils.filter_features(features)]\n",
    "for z in reversed(OUTPUT_ZOOMS):\n",
    "  for t in supermercado.burntiles.burn(features, z):\n",
    "    tile = t.tolist()\n",
    "    #print(tile)\n",
    "    children = mercantile.children(tile)\n",
    "    \n",
    "    temp = numpy.zeros((SOURCE_MAP_TILE_BAND_COUNT, SOURCE_MAP_TILE_HEIGHT_PX*2, SOURCE_MAP_TILE_WIDTH_PX*2), dtype=SOURCE_MAP_TILE_DTYPE)\n",
    "\n",
    "    for y in range(children[1].y, children[3].y+1):\n",
    "      for x in range(children[0].x, children[1].x+1):\n",
    "        try:\n",
    "          path = SOURCE_MAP_TILE_PATH if children[0].z == SRC_ZOOM else OUTPUT_TILE_PATH\n",
    "          child = path + \"/\" + str(children[0].z) + \"/\" + str(x) + \"/\" + str(y) + SOURCE_MAP_TILE_TYPE\n",
    "          with rasterio.open(child) as tile_src:\n",
    "            data_src = tile_src.read()            \n",
    "            temp[:, \n",
    "                (y-children[1].y)*SOURCE_MAP_TILE_HEIGHT_PX:(y-children[1].y+1)*SOURCE_MAP_TILE_HEIGHT_PX, \n",
    "                (x-children[0].x)*SOURCE_MAP_TILE_WIDTH_PX :(x-children[0].x+1)*SOURCE_MAP_TILE_WIDTH_PX] = data_src[:,:,:]\n",
    "        except rasterio.errors.RasterioIOError as e:\n",
    "            pass\n",
    "    dest_path = OUTPUT_TILE_PATH + \"/\" + str(tile[2]) + \"/\" + str(tile[0]) + \"/\" + str(tile[1]) + SOURCE_MAP_TILE_TYPE\n",
    "    os.makedirs(pathlib.Path(dest_path).parent, exist_ok=True)\n",
    "    bb = mercantile.xy_bounds(tile[0], tile[1], tile[2])\n",
    "    tile_tf = rasterio.transform.from_bounds(bb.left, bb.bottom, bb.right, bb.top, SOURCE_MAP_TILE_WIDTH_PX, SOURCE_MAP_TILE_HEIGHT_PX)\n",
    "    with rasterio.open(dest_path, 'w', driver='GTiff',\n",
    "                width=SOURCE_MAP_TILE_WIDTH_PX, height=SOURCE_MAP_TILE_HEIGHT_PX,\n",
    "                count=SOURCE_MAP_TILE_BAND_COUNT, dtype=SOURCE_MAP_TILE_DTYPE, nodata=0,\n",
    "                transform=tile_tf, \n",
    "                crs=rasterio.crs.CRS.from_epsg(SOURCE_MAP_TILE_EPSG)) as dst:\n",
    "      dst.write(temp)\n",
    "    #rasterio.plot.show(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert tiff to png\n",
    "#\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "os.environ['GDAL_PAM_ENABLED'] = 'NO'\n",
    "\n",
    "PATH = 'aerial_images/opendata_luftbild_dop60_2017_wip/'\n",
    "\n",
    "for path in Path(PATH).rglob('*.tiff'):\n",
    "    with rasterio.open(path) as src:\n",
    "      dest_path = path.parent.joinpath(path.stem+'.png')\n",
    "      with rasterio.open(dest_path, 'w',\n",
    "                         driver='PNG',\n",
    "                         height=src.shape[0],\n",
    "                         width=src.shape[1],\n",
    "                         count=src.count,\n",
    "                         dtype=src.meta['dtype'],\n",
    "                         nodata=0,\n",
    "                         compress='deflate') as dst:\n",
    "        dst.write(src.read())\n",
    "\n",
    "#for path in Path(PATH).rglob('*.aux.xml'):\n",
    "#  os.remove(path)\n",
    "\n",
    "for path in Path(PATH).rglob('*.tiff'):\n",
    "  os.remove(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show image and meta info\n",
    "#\n",
    "import rasterio\n",
    "from rasterio import plot\n",
    "\n",
    "PATH = 'temp/png/12/2177/1420.png'\n",
    "\n",
    "with rasterio.open(PATH) as src:\n",
    "  print(src.meta)\n",
    "  rasterio.plot.show(src.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate resolution of an XYZ map tile\n",
    "\n",
    "import math\n",
    "lat = 48.137154\n",
    "z = 18\n",
    "resolution =  -156543.04 * math.cos(lat) / (2**z)\n",
    "resolution # meter per pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"small trees\" labels in labelme annotation json files\n",
    "\n",
    "import glob\n",
    "import math\n",
    "import json\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "ds = 'by_dop80c_1312' # 'opendata_luftbild_dop60_1312' #\n",
    "\n",
    "FILTER_LABEL = \"Tree\"\n",
    "FILTER_TYPE  = \"circle\"\n",
    "FILTER_DIAMETER = 10 # pixel\n",
    "labels = glob.glob('interim/{ds}/deepforest_r1/train2/*.json'.format(ds=ds))\n",
    "\n",
    "def diameter(points):\n",
    "  p1 = points[0]\n",
    "  p2 = points[1]\n",
    "  return 2 * math.sqrt(math.pow(p1[0]-p2[0],2) + math.pow(p1[1]-p2[1],2))\n",
    "\n",
    "def filter(shape):\n",
    "  if shape['label'] == FILTER_LABEL and \\\n",
    "     shape['shape_type'] == FILTER_TYPE and \\\n",
    "     diameter(shape['points']) >= FILTER_DIAMETER:\n",
    "    return True\n",
    "  return False\n",
    "\n",
    "for label in labels:\n",
    "  f = Path(label)\n",
    "  gjson = None\n",
    "  print(f)\n",
    "  with open(f) as json_file:\n",
    "    gjson = json.load(json_file)\n",
    "  gjson['shapes'] = [s for s in gjson['shapes'] if filter(s)]\n",
    "  with open(f, 'w') as outfile:\n",
    "    json.dump(gjson, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate labeme annotation json file from (e.g. deepforest) annotation csv\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "PATH = \"interim/by_dop80c_1312/deepforest_r1/response/crop/\"\n",
    "imageHeight = imageWidth = 1312\n",
    "\n",
    "for c in glob.glob(PATH + \"*.csv_\"):\n",
    "  df = pd.read_csv(c)\n",
    "  files = list(df['image_path'].unique())\n",
    "\n",
    "  for file in files:\n",
    "    label = { \"version\": \"4.5.10\",\n",
    "              \"flags\": {},\n",
    "              \"shapes\": [],\n",
    "              \"imagePath\": Path(file).name,\n",
    "              \"imageData\": None,\n",
    "              \"imageHeight\": imageHeight,\n",
    "              \"imageWidth\": imageWidth\n",
    "            }\n",
    "    bboxes = df[df['image_path'] == file]\n",
    "    for index, row in bboxes.iterrows():\n",
    "      shape = {\n",
    "        \"label\": row[\"label\"],\n",
    "        \"points\": [\n",
    "          [\n",
    "            row[\"xmin\"],\n",
    "            row[\"ymin\"]\n",
    "          ],\n",
    "          [\n",
    "            row[\"xmax\"],\n",
    "            row[\"ymax\"]\n",
    "          ]\n",
    "        ],\n",
    "        \"group_id\": None,\n",
    "        \"shape_type\": \"rectangle\",\n",
    "        \"flags\": {}\n",
    "      }\n",
    "      label[\"shapes\"].append(shape)\n",
    "\n",
    "    dest = PATH + os.path.splitext(file)[0] + \".json\"\n",
    "    with open(dest, 'w') as outfile:\n",
    "      json.dump(label, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate labeme annotation json file from pickl\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import rasterio\n",
    "import torch\n",
    "from torchvision.ops import nms\n",
    "from urbantree.deepforest.detection import run_nms\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "ds = 'opendata_luftbild_dop60_1312' #'by_dop80c_1312' # \n",
    "PICKL_DIR = Path('interim/{ds}/deepforest_r1/predict/b'.format(ds=ds))\n",
    "IMG_DIR = Path('interim/{ds}/deepforest_r1/train2'.format(ds=ds))\n",
    "\n",
    "for f in IMG_DIR.glob('*.tiff'):\n",
    "  with rasterio.open(f) as img:\n",
    "    imageHeight = img.height\n",
    "    imageWidth = img.width\n",
    "\n",
    "  df = pd.read_pickle(PICKL_DIR.joinpath(f.stem + \".pkl\"))\n",
    "  df = run_nms(df, iou_threshold=0.1)\n",
    "\n",
    "  label = { \"version\": \"4.5.10\",\n",
    "              \"flags\": {},\n",
    "              \"shapes\": [],\n",
    "              \"imagePath\": f.name,\n",
    "              \"imageData\": None,\n",
    "              \"imageHeight\": imageHeight,\n",
    "              \"imageWidth\": imageWidth\n",
    "            }\n",
    "  for index, row in df.iterrows():\n",
    "    shape = {\n",
    "        \"label\": row.label,\n",
    "        \"points\": [\n",
    "          [\n",
    "            (row.xmin + row.xmax)/2.0,\n",
    "            (row.ymin + row.ymax)/2.0\n",
    "          ],\n",
    "          [\n",
    "            (row.xmin + row.xmax)/2.0,\n",
    "            row.ymax\n",
    "          ]\n",
    "        ],\n",
    "        \"group_id\": None,\n",
    "        \"shape_type\": \"circle\",\n",
    "        \"flags\": {}\n",
    "      }\n",
    "    label[\"shapes\"].append(shape)\n",
    "  dest = IMG_DIR.joinpath(f.stem +\".json\")\n",
    "  with open(dest, 'w') as outfile:\n",
    "    json.dump(label, outfile, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file('temp/diff2/diff.geojson')\n",
    "gdf.to_file('temp/diff2/diff.shp')\n",
    "#gdf.to_file(\"temp/diff2/diff.export.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overpass API for querying Admin boundary\n",
    "\n",
    "## {{geocodeArea:Munich}}->.searchArea;\n",
    "## (\n",
    "##   //node[\"admin_level\"=\"9\"](area.searchArea);\n",
    "##   //way[\"admin_level\"=\"9\"](area.searchArea);\n",
    "##   relation[\"admin_level\"=\"9\"](area.searchArea);\n",
    "## );\n",
    "## out body;\n",
    "## >;\n",
    "## out skel qt;\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "# boundary\n",
    "city = gpd.read_file('contrib/munich/munich.boundary.geojson')\n",
    "district = gpd.read_file('contrib/munich/munich-admin.boundary.geojson')\n",
    "\n",
    "# calculated missing tree\n",
    "missing= gpd.read_file('contrib/munich/missing-2017-2020.geojson')\n",
    "\n",
    "missing_city = gpd.clip(missing, city)\n",
    "missing_city.to_file(\"temp/missing/missing-tree-in-city-2017-2020.shp\")\n",
    "\n",
    "for _, row in district.iterrows():\n",
    "  name = row['name'].replace(' ', '_')\n",
    "  missing_district = gpd.clip(missing, row.geometry)\n",
    "  missing_district.to_file(\"temp/missing/missing-tree-in-dist-{d}-2017-2020.shp\".format(d=name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d17c320a108ed353692a9d869777d22c4cfc8e217512b3979b490c9a0e17a049"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('detectree': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
